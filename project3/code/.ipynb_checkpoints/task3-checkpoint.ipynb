{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mylibrary import count_pixels\n",
    "import task1\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sober for edge detection\n",
    "VERTICAL_SOBEL_3BY3 = np.array([[-1,2,-1],\n",
    "                          [-1,2,-1],\n",
    "                          [-1,2,-1]])\n",
    "\n",
    "HORIZONTAL_SOBEL_3BY3 = np.array([[-1,-1,-1],\n",
    "                         [2,2,2],\n",
    "                         [-1,-1,-1]])\n",
    "POS45_SOBEL_3BY3 = np.array([[-1,-1,2],\n",
    "                         [-1,2,-1],\n",
    "                         [2,-1,-1]])\n",
    "NEG45_SOBEL_3BY3 = np.array([[2,-1,-1],\n",
    "                         [-1,2,-1],\n",
    "                         [-1,-1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texture_filtering(img_gray, kernel):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        use to filter the gray image given the kernel\n",
    "    Input:\n",
    "        img_gray: \n",
    "            an two dimension ndarray matrix, dtype:usually is uint8 representint the gray image.\n",
    "        kernel: \n",
    "            a two dimension ndarray matrix\n",
    "    Output:\n",
    "        The filtered image without padding around.\n",
    "    \"\"\"\n",
    "    row_pad = math.floor(kernel.shape[0] / 2)\n",
    "    col_pad = math.floor(kernel.shape[1] / 2)\n",
    "    \n",
    "    res_img = np.zeros(img_gray.shape)\n",
    "    check_img = np.pad(img_gray, ((row_pad,row_pad),(col_pad, col_pad)), 'constant')\n",
    "    flipped_kernel = np.flip(kernel)\n",
    "    \n",
    "    for i in range(row_pad, check_img.shape[0] - row_pad):\n",
    "        for j in range(col_pad, check_img.shape[1] - col_pad):\n",
    "            patch = check_img[i-row_pad:i+row_pad+1, j-col_pad:j+col_pad+1]\n",
    "            res_img[i-row_pad, j-col_pad] = np.sum(patch * flipped_kernel)\n",
    "    return res_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_zero(img, method=1):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        two ways to eliminate the negative value or the value out of 255.\n",
    "    Input:\n",
    "        img: two dimension matrix\n",
    "            the raw image. dtype usually is float64 with pixel < 0 or pixel > 255\n",
    "        method: int\n",
    "            default is 1 which directs to first method\n",
    "            the 2 will direct to the second method.\n",
    "    Output:\n",
    "        a matrix dtype range zero to one. \n",
    "    \"\"\"\n",
    "    if method == 1:\n",
    "        min_ = np.min(img)\n",
    "        max_ = np.max(img)\n",
    "        return (img - min_) / (max_ - min_)\n",
    "    elif method == 2:\n",
    "        abs_img = np.abs(img)\n",
    "        return abs_img / np.max(abs_img)\n",
    "    else :\n",
    "        print(\"method is 1 or 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_edge(hori,vert,pos45,neg45,T):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        to combine edges in four direction. \n",
    "        Mark result image 1 in given loc if any of these four edge images pixels absolute value\n",
    "        greater than T in that loc.\n",
    "    Output:\n",
    "        res_img: binary img, value type np.uint8\n",
    "    \"\"\"\n",
    "    hori = np.abs(hori)\n",
    "    vert = np.abs(vert)\n",
    "    pos45 = np.abs(pos45)\n",
    "    neg45 = np.abs(neg45)\n",
    "    res_img = np.zeros(hori.shape).astype(np.uint8)\n",
    "    for i in range(hori.shape[0]):\n",
    "        for j in range(hori.shape[1]):\n",
    "            if hori[i,j] > T or vert[i,j] > T or pos45[i,j] > T or neg45[i,j] > T :\n",
    "                res_img[i,j] = 1\n",
    "    return res_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_border(img_gray):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        ignore the img bodre by setting value as 0.\n",
    "        notice: Affect original img.\n",
    "    Output:\n",
    "        the pointer point to original image.\n",
    "    \"\"\"\n",
    "    img_gray[0] = 0\n",
    "    img_gray[-1] = 0\n",
    "    for row in img_gray:\n",
    "        row[0] = 0\n",
    "        row[-1] = 0\n",
    "    return img_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_by_count(lines, T):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        filter the lines which number of (rho, radian) greater than threshold T.\n",
    "    Input:\n",
    "        lines: a matrix, col_1: rho, col_2: radian, col_2: number of (rho, radian) tuple. It can be got by res_dic.\n",
    "    Output:\n",
    "        matrix, numpy array, each row represent a selected line. \n",
    "        \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for line in lines:\n",
    "        if line[2] > T:\n",
    "            res.append(line)  \n",
    "    return np.asarray(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_by_theta(lines, theta, gap):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        filter the lines by theta,\n",
    "    Input:\n",
    "        lines: a matrix, col_1: rho, col_2: radian, col_2: number of (rho, radian) tuple.\n",
    "        theta: real, is a radian, will compared radians from col_2\n",
    "        gap: the maximum difference between two theta.\n",
    "    Output:\n",
    "        matrix, numpy array, each row represent a selected line. \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for line in lines:\n",
    "        if abs(line[1] - theta) < gap:\n",
    "            res.append(line)  \n",
    "    return np.asarray(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough(edge_img):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Main function of hough transform.\n",
    "        Notice: Here I use the rho = x * sin(theta) + y * cos(theta). It is different from the hough equation.\n",
    "        I do this to meet the convention of opencv so that to use opencv library easily later.\n",
    "    Input:\n",
    "        edge_img: binary image, the boundary image after edge detection.\n",
    "    Output:\n",
    "        res_dic: a dictionary, key is a tuple (rho, radian), value is the number of its key.\n",
    "    \"\"\"\n",
    "    m, n = edge_img.shape\n",
    "    res_dic = {}\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if edge_img[i,j] == 1:\n",
    "                for degree in range(0,180):\n",
    "                    radian = np.radians(degree)\n",
    "                    rho = int(i * np.sin(radian) + j * np.cos(radian))\n",
    "                    if ((rho, radian)) not in res_dic:\n",
    "                        res_dic[(rho, radian)] = 0\n",
    "                    res_dic[(rho, radian)] += 1\n",
    "    return res_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img, lines, loc=\"../task3_img/\", name = \"hough_res.jpg\"):\n",
    "    \"\"\"\n",
    "    Purpose: \n",
    "        draw lines in image\n",
    "        not affect original imgage.\n",
    "    \"\"\"\n",
    "    img = img.copy()\n",
    "    for line in lines:\n",
    "        rho = line[0]\n",
    "        theta = line[1]\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "    cv2.imwrite(loc+name, img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle_hough(edge_img):\n",
    "    res_dic = {}\n",
    "    for x in range(edge_img.shape[0]):\n",
    "        for y in range(edge_img.shape[1]):\n",
    "            if edge_img[x,y] == 1:\n",
    "                for r in range(18,28):\n",
    "                    for t in range(0,360):\n",
    "                        a = x - r * np.cos(t * np.pi / 180)\n",
    "                        b = y - r * np.sin(t * np.pi / 180)\n",
    "                        if (a,b,r) not in res_dic:\n",
    "                            res_dic[(a,b,r)] = 0\n",
    "                        res_dic[(a,b,r)] += 1\n",
    "    return res_dic       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circles(img, circles, loc=\"../task3_img/\", name=\"coin.jpg\" ):\n",
    "    img = img.copy()\n",
    "    for cir in circles:\n",
    "        cv2.circle(img,(cir[1], cir[0]), cir[2], (0,255,0), 1)\n",
    "    cv2.imwrite(loc+name, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to do edge detection\n",
      "Start to preprocess binary image\n",
      "Start using hough algorithms\n",
      "start hough circle\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    img = cv2.imread('../task3_img/hough.jpg')\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    print(\"Start to do edge detection\")\n",
    "    ## get edges from four directions\n",
    "    vertical = texture_filtering(img_gray, VERTICAL_SOBEL_3BY3)\n",
    "    horizontal = texture_filtering(img_gray, HORIZONTAL_SOBEL_3BY3)\n",
    "    pos45 = texture_filtering(img_gray, POS45_SOBEL_3BY3)\n",
    "    neg45 = texture_filtering(img_gray, NEG45_SOBEL_3BY3)\n",
    "    \n",
    "    ## Find threshold through observation\n",
    "    # vertical\n",
    "    pixel_stat = count_pixels(np.abs(vertical))\n",
    "    stat_list = np.asarray([[key,val] for key,val in pixel_stat.items() if key >100]).T\n",
    "    plt.bar(stat_list[0],stat_list[1],align='center') # A bar chart\n",
    "    plt.title(\"pixel numbers count (vert edge, value > 100)\")\n",
    "    plt.xlabel('pixel value')\n",
    "    plt.ylabel('number')\n",
    "    plt.savefig(\"../task3_img/vert_hist\")\n",
    "    plt.close()\n",
    "    \n",
    "    #horizontal\n",
    "    pixel_stat = count_pixels(np.abs(horizontal))\n",
    "    stat_list = np.asarray([[key,val] for key,val in pixel_stat.items() if key >100]).T\n",
    "    plt.bar(stat_list[0],stat_list[1],align='center') # A bar chart\n",
    "    plt.title(\"pixel numbers count (hori edge, value > 100)\")\n",
    "    plt.xlabel('pixel value')\n",
    "    plt.ylabel('number')\n",
    "    plt.savefig(\"../task3_img/hori_hist\")\n",
    "    plt.close()\n",
    "    \n",
    "    #pos45\n",
    "    pixel_stat = count_pixels(np.abs(pos45))\n",
    "    stat_list = np.asarray([[key,val] for key,val in pixel_stat.items() if key >100]).T\n",
    "    plt.bar(stat_list[0],stat_list[1],align='center') # A bar chart\n",
    "    plt.title(\"pixel numbers count (pos45 edge, value > 100)\")\n",
    "    plt.xlabel('pixel value')\n",
    "    plt.ylabel('number')\n",
    "    plt.savefig(\"../task3_img/pos45_hist\")\n",
    "    plt.close()\n",
    "    \n",
    "    #neg45\n",
    "    pixel_stat = count_pixels(np.abs(neg45))\n",
    "    stat_list = np.asarray([[key,val] for key,val in pixel_stat.items() if key >100]).T\n",
    "    plt.bar(stat_list[0],stat_list[1],align='center') # A bar chart\n",
    "    plt.title(\"pixel numbers count (neg45, value > 100)\")\n",
    "    plt.xlabel('pixel value')\n",
    "    plt.ylabel('number')\n",
    "    plt.savefig(\"../task3_img/neg45_hist\")\n",
    "    plt.close()\n",
    "    \n",
    "    ## Combined edges using threshold\n",
    "    T = 50\n",
    "    combined = combine_edge(horizontal,vertical,pos45,neg45,T)\n",
    "    combined = ignore_border(combined)\n",
    "    cv2.imwrite(\"../task3_img/combined.jpg\", (combined*255).astype(np.uint8))\n",
    "    \n",
    "    ## preprocess binary image\n",
    "    print(\"Start to preprocess binary image\")\n",
    "    #denoise\n",
    "    struc_elem = np.ones((3,3)).astype(np.uint8)\n",
    "    denoised = task1.denoising(method=2)(combined, struc_elem)\n",
    "    cv2.imwrite(\"../task3_img/denoised.jpg\", (denoised*255).astype(np.uint8))\n",
    "    #closing\n",
    "    struc_elem = np.ones((7,7)).astype(np.uint8)\n",
    "    closed = task1.closing(denoised, struc_elem)\n",
    "    cv2.imwrite(\"../task3_img/closed.jpg\", (closed*255).astype(np.uint8))\n",
    "    #extract boundary\n",
    "    boundary = task1.boundary(closed)\n",
    "    cv2.imwrite(\"../task3_img/boundary.jpg\", (boundary*255).astype(np.uint8))\n",
    "    \n",
    "    ## Start using hough algorithms\n",
    "    print(\"Start using hough algorithms\")\n",
    "    hres = hough(boundary)\n",
    "    lines = np.asarray([[key[0], key[1], val] for key, val in hres.items()])\n",
    "    #filter by theta and count\n",
    "    #red lines\n",
    "    T = 160\n",
    "    theta_gap = 0.2\n",
    "    theta_red = 3.1\n",
    "    lines_red = pick_by_theta(lines, theta_red, theta_gap)\n",
    "    res_red = pick_by_count(lines_red, T)\n",
    "    draw_lines(img, res_red, loc=\"../task3_img/\", name = \"red_line.jpg\")\n",
    "\n",
    "    #blue lines\n",
    "    T = 140\n",
    "    theta_gap = 0.2\n",
    "    theta_blue = 2.5\n",
    "    lines_blue = pick_by_theta(lines, theta_blue, theta_gap)\n",
    "    res_blue = pick_by_count(lines_blue, T)\n",
    "    draw_lines(img, res_blue, loc=\"../task3_img/\", name = \"blue_lines.jpg\")\n",
    "    \n",
    "    #Bonus Circle hough\n",
    "    print(\"start hough circle\")\n",
    "    chres = circle_hough(boundary)\n",
    "    circles = [item for item in chres.items() if chres[item[0]] >= 4]\n",
    "    circles = np.asarray([[x[0][0], x[0][1], x[0][2], x[1]] for x in circles]).astype(int)\n",
    "    draw_circles(img, circles)\n",
    "    #Bonus using Canny edge detection\n",
    "#     img = cv2.imread('../task3_img/hough.jpg')\n",
    "#     gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#     edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "#     chres = circle_hough(edges)\n",
    "#     circles = [item for item in chres.items() if chres[item[0]] >= 4]\n",
    "#     circles = np.asarray([[x[0][0], x[0][1], x[0][2], x[1]] for x in circles]).astype(int)\n",
    "#     draw_circles(img, circles, name=\"coin_edge.jpg\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('../task3_img/hough.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "cv2.imwrite('../task3_img/cannyedge.jpg', edges) \n",
    "edges = (edges/255).astype(np.uint)\n",
    "struc_elem = np.ones((7,7)).astype(np.uint8)\n",
    "closed = task1.closing(edges, struc_elem)\n",
    "boundary3 = task1.boundary(closed)\n",
    "cv2.imwrite(\"../task3_img/boundary3.jpg\", (boundary3*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=uint64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chres = circle_hough(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76927137"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(503.0, 0.9999999999999967, 27)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(chres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circles = [item for item in chres.items() if chres[item[0]] >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((45.0, 268.0, 18), 4),\n",
       " ((48.0, 269.0, 19), 4),\n",
       " ((48.0, 271.0, 19), 4),\n",
       " ((48.0, 275.0, 19), 4),\n",
       " ((47.0, 276.0, 18), 4),\n",
       " ((55.0, 373.0, 19), 4),\n",
       " ((55.0, 376.0, 19), 4),\n",
       " ((56.0, 373.0, 18), 4),\n",
       " ((56.0, 376.0, 18), 4),\n",
       " ((67.0, 541.0, 25), 4),\n",
       " ((65.0, 543.0, 20), 4),\n",
       " ((69.0, 541.0, 23), 4),\n",
       " ((69.0, 544.0, 22), 4),\n",
       " ((72.0, 542.0, 24), 4),\n",
       " ((68.0, 148.0, 19), 4),\n",
       " ((68.0, 543.0, 18), 4),\n",
       " ((73.0, 381.0, 20), 4),\n",
       " ((74.0, 378.0, 20), 4),\n",
       " ((83.0, 516.0, 18), 4),\n",
       " ((84.0, 125.0, 18), 4),\n",
       " ((89.0, 131.0, 20), 4),\n",
       " ((90.0, 130.0, 18), 4),\n",
       " ((100.0, 500.0, 27), 4),\n",
       " ((127.0, 588.0, 22), 4),\n",
       " ((129.0, 589.0, 23), 4),\n",
       " ((130.0, 587.0, 21), 4),\n",
       " ((131.0, 587.0, 21), 4),\n",
       " ((132.0, 591.0, 22), 4),\n",
       " ((132.0, 610.0, 19), 4),\n",
       " ((136.0, 603.0, 22), 4),\n",
       " ((135.0, 602.0, 18), 4),\n",
       " ((135.0, 611.0, 18), 4),\n",
       " ((144.0, 405.0, 25), 4),\n",
       " ((137.0, 599.0, 18), 4),\n",
       " ((148.0, 407.0, 26), 4),\n",
       " ((149.0, 407.0, 26), 4),\n",
       " ((156.0, 69.0, 18), 4),\n",
       " ((159.0, 70.0, 21), 4),\n",
       " ((157.0, 63.0, 18), 4),\n",
       " ((159.0, 74.0, 19), 4),\n",
       " ((167.0, 378.0, 27), 4),\n",
       " ((159.0, 67.0, 18), 4),\n",
       " ((168.0, 378.0, 27), 4),\n",
       " ((164.0, 425.0, 20), 4),\n",
       " ((172.0, 381.0, 27), 4),\n",
       " ((167.0, 425.0, 20), 4),\n",
       " ((174.0, 381.0, 26), 4),\n",
       " ((174.0, 381.0, 25), 4),\n",
       " ((177.0, 381.0, 27), 4),\n",
       " ((181.0, 248.0, 27), 4),\n",
       " ((181.0, 250.0, 26), 4),\n",
       " ((181.0, 250.0, 25), 4),\n",
       " ((184.0, 406.0, 26), 4),\n",
       " ((177.0, 252.0, 18), 4),\n",
       " ((181.0, 253.0, 22), 4),\n",
       " ((186.0, 406.0, 26), 4),\n",
       " ((181.0, 257.0, 20), 4),\n",
       " ((183.0, 257.0, 22), 4),\n",
       " ((184.0, 405.0, 23), 4),\n",
       " ((181.0, 259.0, 18), 4),\n",
       " ((184.0, 260.0, 19), 4),\n",
       " ((187.0, 257.0, 21), 4),\n",
       " ((188.0, 258.0, 22), 4),\n",
       " ((186.0, 259.0, 19), 4),\n",
       " ((190.0, 259.0, 23), 4),\n",
       " ((191.0, 261.0, 24), 4),\n",
       " ((193.0, 262.0, 25), 4),\n",
       " ((193.0, 263.0, 25), 4),\n",
       " ((192.0, 236.0, 21), 4),\n",
       " ((191.0, 237.0, 20), 4),\n",
       " ((190.0, 264.0, 19), 4),\n",
       " ((191.0, 264.0, 20), 4),\n",
       " ((195.0, 264.0, 24), 4),\n",
       " ((196.0, 265.0, 25), 4),\n",
       " ((190.0, 242.0, 18), 4),\n",
       " ((192.0, 242.0, 20), 4),\n",
       " ((195.0, 262.0, 23), 4),\n",
       " ((192.0, 266.0, 20), 4),\n",
       " ((193.0, 262.0, 20), 4),\n",
       " ((195.0, 262.0, 22), 4),\n",
       " ((193.0, 267.0, 20), 4),\n",
       " ((193.0, 234.0, 18), 4),\n",
       " ((193.0, 236.0, 18), 4),\n",
       " ((193.0, 243.0, 18), 4),\n",
       " ((194.0, 264.0, 19), 4),\n",
       " ((195.0, 233.0, 19), 4),\n",
       " ((194.0, 265.0, 18), 4),\n",
       " ((198.0, 265.0, 22), 4),\n",
       " ((199.0, 268.0, 23), 4),\n",
       " ((196.0, 283.0, 20), 4),\n",
       " ((200.0, 270.0, 23), 4),\n",
       " ((198.0, 267.0, 20), 4),\n",
       " ((200.0, 276.0, 19), 4),\n",
       " ((203.0, 282.0, 22), 4),\n",
       " ((204.0, 273.0, 21), 4),\n",
       " ((204.0, 274.0, 21), 4),\n",
       " ((204.0, 278.0, 21), 4),\n",
       " ((206.0, 214.0, 22), 4),\n",
       " ((204.0, 275.0, 18), 4),\n",
       " ((205.0, 215.0, 18), 4),\n",
       " ((206.0, 285.0, 19), 4),\n",
       " ((205.0, 286.0, 18), 4),\n",
       " ((209.0, 380.0, 19), 4),\n",
       " ((212.0, 386.0, 20), 4),\n",
       " ((212.0, 379.0, 19), 4),\n",
       " ((213.0, 221.0, 18), 4),\n",
       " ((220.0, 388.0, 18), 4),\n",
       " ((252.0, 49.0, 20), 4),\n",
       " ((251.0, 50.0, 19), 4),\n",
       " ((250.0, 53.0, 18), 4),\n",
       " ((253.0, 42.0, 18), 4),\n",
       " ((254.0, 46.0, 18), 4),\n",
       " ((256.0, 51.0, 20), 4),\n",
       " ((255.0, 51.0, 18), 4),\n",
       " ((258.0, 47.0, 18), 4),\n",
       " ((344.0, 550.0, 27), 4),\n",
       " ((345.0, 548.0, 26), 4),\n",
       " ((348.0, 550.0, 27), 4),\n",
       " ((346.0, 550.0, 24), 4),\n",
       " ((346.0, 551.0, 23), 4),\n",
       " ((348.0, 551.0, 24), 4),\n",
       " ((343.0, 556.0, 18), 4),\n",
       " ((349.0, 556.0, 19), 4),\n",
       " ((349.0, 556.0, 18), 4),\n",
       " ((363.0, 529.0, 20), 4),\n",
       " ((361.0, 538.0, 18), 4),\n",
       " ((371.0, 121.0, 19), 4),\n",
       " ((373.0, 121.0, 19), 4),\n",
       " ((374.0, 122.0, 20), 4),\n",
       " ((380.0, 139.0, 21), 4),\n",
       " ((380.0, 142.0, 21), 4),\n",
       " ((380.0, 137.0, 19), 4),\n",
       " ((381.0, 140.0, 20), 4),\n",
       " ((382.0, 143.0, 19), 4),\n",
       " ((392.0, 407.0, 20), 4),\n",
       " ((396.0, 410.0, 20), 4),\n",
       " ((397.0, 432.0, 18), 4),\n",
       " ((416.0, 47.0, 20), 4)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circles = np.asarray([[x[0][0], x[0][1], x[0][2], x[1]] for x in circles]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_circles(img, circles, name=\"coin_edge.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struc_elem = np.ones((5,5)).astype(np.uint8)\n",
    "boundary2 = task1.dilation(boundary, struc_elem)\n",
    "boundary2 = task1.boundary(boundary2)\n",
    "cv2.imwrite(\"../task3_img/boundary2.jpg\", boundary2*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.copy()\n",
    "    for line in lines:\n",
    "        rho = line[0]\n",
    "        theta = line[1]\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "    cv2.imwrite(loc+name, img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((135.0, 279.0, 45), 4),\n",
       " ((267.0, 292.0, 44), 4),\n",
       " ((268.0, 293.0, 45), 4),\n",
       " ((279.0, 384.0, 45), 4),\n",
       " ((311.0, 245.0, 48), 4),\n",
       " ((329.0, 427.0, 51), 4),\n",
       " ((401.0, 102.0, 47), 4)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.circle(img,(447,63), 63, (0,0,255), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48397244"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'edge_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-21521cb866ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0medge_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'edge_img' is not defined"
     ]
    }
   ],
   "source": [
    "edge_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For each pixel(x,y)\n",
    "    For each radius r = 10 to r = 60 // the possible radius\n",
    "      For each theta t = 0 to 360  // the possible  theta 0 to 360 \n",
    "         a = x – r * cos(t * PI / 180); //polar coordinate for center\n",
    "         b = y – r * sin(t * PI / 180);  //polar coordinate for center \n",
    "         A[a,b,r] +=1; //voting\n",
    "      end\n",
    "    end\n",
    "  end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin1 = cv2.imread('../task3_img/coin1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 50, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin2 = cv2.imread('../task3_img/coin2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 47, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "40 to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hough Transform in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('img', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('../task3_img/hough.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "cv2.imwrite('../task3_img/cannyedge.jpg', edges) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255,   0,   0, ...,   0,   0,   0],\n",
       "       [255,   0,   0, ...,   0,   0,   0],\n",
       "       [255,   0,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0, 255,   0, ...,   0,   0,   0],\n",
       "       [  0, 255,   0, ...,   0,   0,   0],\n",
       "       [  0, 255,   0, ...,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength=100,maxLineGap=10)\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "    #cv2.imwrite('houghlines5.jpg',img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('img', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 448,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hough Circle Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../task3_img/hough.jpg',0)\n",
    "img = cv2.medianBlur(img,5)\n",
    "cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "img = inv_binary_img(img, 127) *255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "circles = cv2.HoughCircles(img,cv2.HOUGH_GRADIENT,1,20, param1=50,param2=30,minRadius=0,maxRadius=0)\n",
    "circles = np.uint16(np.around(circles))\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    # draw the center of the circle\n",
    "    cv2.circle(cimg,(i[0],i[1]),2,(0,0,255),3)\n",
    "    \n",
    "cv2.imshow('detected circles',cimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_binary_img(img_gray, T):\n",
    "    res_img = np.zeros(img.shape).astype(np.uint8)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if img[i,j] < T:\n",
    "                res_img[i,j] = 1\n",
    "    return res_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pixel(gray_img):\n",
    "    pdict = {}\n",
    "    for row in img:\n",
    "        for val in row:\n",
    "            if val not in pdict:\n",
    "                pdict[val] = 0\n",
    "            pdict[val] += 1\n",
    "    return pdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../task3_img/hough.jpg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdict = count_pixel(img)\n",
    "pdict = count_pixel(img)\n",
    "plist = np.asarray([[key,val] for key,val in pdict.items() if key != 0])\n",
    "plist_t = plist.T\n",
    "plt.bar(plist_t[0],plist_t[1],align='center') # A bar chart\n",
    "plt.xlabel('Bins')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../task3_img/hough.jpg',0)\n",
    "edges = cv2.Canny(img,50,150,apertureSize = 3)\n",
    "cv2.namedWindow('edges', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('edges', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../task3_img/hough.jpg',0)\n",
    "res_img = inv_binary_img(img, 127) * 255\n",
    "cv2.namedWindow('res_img', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('res_img', res_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.imread('../task3_img/hough.jpg')\n",
    "img = cv2.imread('../task3_img/hough.jpg',0)\n",
    "img = cv2.medianBlur(img,5)\n",
    "th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                            cv2.THRESH_BINARY,11,2)\n",
    "#plt.imshow(th3, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "th3_inv = inv_binary_img(th3, 127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = cv2.HoughLines(th3_inv,1,np.pi/180,200)\n",
    "for line in lines:\n",
    "    rho,theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "    cv2.line(img2,(x1,y1),(x2,y2),(0,0,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('img2', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('img2', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depreciated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unused\n",
    "def magnitude_edges(edge_x, edge_y):\n",
    "    \"\"\"\n",
    "    Purpose: \n",
    "        Combine the vertical image and horizontal image.\n",
    "    Input:\n",
    "        edge_x: two dimension matrix\n",
    "            the image filted by VERTICAL_SOBEL\n",
    "        edge_y: two dimension matrix\n",
    "            the image filted by HORIZONTAL_SOBEL\n",
    "    Output:\n",
    "        edge_magnitude: two dimension matrix\n",
    "            the image combined by edge_x and edge_y\n",
    "        \n",
    "    \"\"\"\n",
    "    edge_magnitude = np.sqrt(edge_x ** 2 + edge_y ** 2)\n",
    "    max_ = np.max(edge_magnitude)\n",
    "    edge_magnitude /= max_\n",
    "    return edge_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectname",
   "language": "python",
   "name": "projectname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
